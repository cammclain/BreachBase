# `docs/planning/v0/4.md`


---


So you suggested we divide the `.env` files up for each node. I think this is a good idea. But I want to do this in a way that makes it easy for random users to get started, since I am open sourcing this.

So I am thinking we should have a single `example.env` file that has all the variables in it.
when the user clones the repo, they can just copy the `example.env` file to `.env` and then fill in the values.

something like this:

```bash
cp example.env .env
```

and then we will have a `setup.sh` script that will break down the `.env` file into the individual `.env` files for each node.

So we will end up with something like this:

```txt
.env
src/master_node/.env
src/worker_node/.env
src/ollama_node/.env
```


---

for #2, as you suggested I will be changing the `src/master_node/services/step_ca/Dockerfile` to use a `Debian` slim image with `step-ca` installed on the Debian container instead of the `smallstep/step-ca` image.

This will make it easier to copy the `config/smallstep_ca.json` file to the container and use it as the CA configuration.

----

for #3 I have started to work on the `src/worker_node/services/scanner/application/app/scans/hosts.py`, and the `src/worker_node/services/scanner/application/app/scans/discovery/scans.py` file.

These look like this:



`src/worker_node/services/scanner/application/app/scans/hosts.py`

```python
from __future__ import annotations

from temporalio import workflow

from dataclasses import dataclass


@dataclass
class Service:
    port: int
    protocol: str

@dataclass
class Host:
    ip: str
    port: int
    protocol: str
    services: list[Service]


@workflow.defn(name="ScanHosts")
class ScanHosts:
    @workflow.run
    async def run(self) -> None:
        pass





```


and `src/worker_node/services/scanner/application/app/scans/discovery/scans.py`

```python
from __future__ import annotations

from temporalio import activity
from bbot.scanner import Scanner
from app.scans.hosts import Host

@activity.defn(name="PortScan")
async def port_scan(self, host: Host) -> None:
    scanner: Scanner = Scanner()
    scanner.scan(host.ip)

    return scanner.results


@activity.defn(name="ServiceScan")
async def service_scan(self, host: Host) -> None:
    pass



@activity.defn(name="VulnScan")
async def vuln_scan(self, host: Host) -> None:
    pass


```

I also added a `src/worker_node/services/scanner/application/main.py` file that has a `main` function that will start the Temporal worker.



----


for #4 you suggested I create a Temporal activity that fetches data from SurrealDB and sends it to Ollama for summarization:


That got me thinking and I began fleshing out the `ollama_node` service.

here is what I have so far:

```bash
(.venv) vscode ➜ /workspaces/BreachBase/src/ollama_node (main) $ tree .
.
├── docker-compose.yml
└── services
    ├── ollama_service
    │   ├── Dockerfile
    │   ├── entrypoint.sh
    │   └── model_files
    └── summarizer_service
        ├── application
        │   ├── app
        │   │   ├── __init__.py
        │   │   ├── reporter.py
        │   │   ├── researcher.py
        │   │   └── summarizer.py
        │   └── main.py
        ├── Dockerfile
        ├── entrypoint.sh
        └── requirements.txt

6 directories, 11 files
```

I created `src/ollama_node/services/summarizer_service/application/app/summarizer.py` file that has the `SummarizeScanResults` activity.




---

For #5 you suggested I set up the XMPP server stuff.

I cleaned up the `src/master_node/services/xmpp_server/entrypoint.sh` file to set up the XMPP server. Eventually we will come back and have a more robust XMPP server setup, that reads the `config/prosody.cfg.lua` file and uses that to set up the XMPP server and uses the `.env` for the variables. 

----

For #6 you suggested i set up the nginx stuff.

I also added the suggested health check route to the `src/master_node/services/dashboard/application/routes/base.py` file.



----

For #7 you suggested i set up the service workflow for the worker node to fetch tasks from the mqtt broker and send them to the Temporal worker.


---



for #8 you suggested i set up the seaweedfs stuff.

i added a `src/master_node/services/seaweedfs_filesystem/Dockerfile` file that has the Dockerfile for the seaweedfs filsystem.

and an `src/master_node/services/seaweedfs_filesystem/entrypoint.sh` file that has the entrypoint for the seaweedfs filsystem.


---






Overall, I am making good progress on the project. 


One thing I am worried about is defining the data structures / models across the various services.

I am thinking I should create a `src/shared/models.py` file that has the data structures / models for the project.

Then I can import these models into each service as needed.

This will help us avoid duplication and ensure consistency across the various services.


here is the overall file structure:

```bash
(.venv) vscode ➜ /workspaces/BreachBase (main) $ tree .
.
├── config
│   ├── certificates
│   └── smallstep_ca.json
├── docs
│   ├── documentation
│   │   ├── api
│   │   └── architecture.md
│   └── planning
│       └── v0
│           ├── 1.md
│           ├── 2.md
│           ├── 3.md
│           └── 4.md
├── example.env
├── README.md
├── requirements.txt
└── src
    ├── master_node
    │   ├── docker-compose.yml
    │   └── services
    │       ├── dashboard
    │       │   ├── application
    │       │   │   ├── __init__.py
    │       │   │   └── routes
    │       │   │       ├── base.py
    │       │   │       └── __init__.py
    │       │   ├── asgi.py
    │       │   ├── Dockerfile
    │       │   ├── entrypoint.sh
    │       │   └── requirements.txt
    │       ├── mqtt_broker
    │       │   └── Dockerfile
    │       ├── nginx_frontend
    │       │   ├── Dockerfile
    │       │   ├── entrypoint.sh
    │       │   ├── nginx.conf
    │       │   └── torrc
    │       ├── seaweedfs_filesystem
    │       │   ├── Dockerfile
    │       │   └── entrypoint.sh
    │       ├── step_ca
    │       │   ├── Dockerfile
    │       │   └── entrypoint.sh
    │       ├── surrealdb_database
    │       │   └── Dockerfile
    │       ├── temporal
    │       │   └── Dockerfile
    │       └── xmpp_server
    │           ├── Dockerfile
    │           └── entrypoint.sh
    ├── ollama_node
    │   ├── docker-compose.yml
    │   └── services
    │       ├── ollama_service
    │       │   ├── Dockerfile
    │       │   ├── entrypoint.sh
    │       │   └── model_files
    │       └── summarizer_service
    │           ├── application
    │           │   ├── app
    │           │   │   ├── __init__.py
    │           │   │   ├── reporter.py
    │           │   │   ├── researcher.py
    │           │   │   └── summarizer.py
    │           │   └── main.py
    │           ├── Dockerfile
    │           ├── entrypoint.sh
    │           └── requirements.txt
    ├── shared
    │   └── models.py
    └── worker_node
        ├── docker-compose.yml
        └── services
            ├── relay
            │   ├── Dockerfile
            │   ├── entrypoint.sh
            │   └── requirements.txt
            └── scanner
                ├── application
                │   ├── app
                │   │   ├── __init__.py
                │   │   └── scans
                │   │       ├── discovery
                │   │       │   ├── __init__.py
                │   │       │   └── scans.py
                │   │       ├── hosts.py
                │   │       └── __init__.py
                │   └── main.py
                ├── Dockerfile
                ├── entrypoint.sh
                └── requirements.txt

36 directories, 55 files
```


