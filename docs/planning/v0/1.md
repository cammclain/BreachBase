I have been tasked with developing an internal tool for my red team firm, where we emulate APTs 

Anyway the internal tool is a database that is designed to be something along the lines of a self hosted alternative to censys shodan or zoomeye. It is similar to IVRE (ivre.rocks) but it is optimized for operational security, and uses self hosted LLMs via Ollama to generate more detailed reports and analysis on the hosts we ingest into the database 

I have been told the system is to be built using surrealDB as the main storage space for information about hosts we scan.

Scans will be preformed using bbot by black lantern security 


I want it to use Ollama agents to generate reports on the hosts that the system comes across, with a focus on discussing how they are vulnerable and how they could potentially be exploited. 


In terms of user interface, I want to make it a dashboard accessible via Tor hidden services which we will expose via an nginx reverse proxy since my teammates and I all work in Whonix workstations

I want to use Litestar as the ASGI framework 

I want to use bulma css for styling (No JavaScript)

I want to use seaweedFS as blob storage and index it using surrealDB 

I think I will use temporal to manage the scans and state of the system. This will require a Postgres database but it should not be used as the main database for scan information. I would like that to be the surrealDB database 

For the overall infrastructure of the system I intend to build this using podman compose 
I want to distribute the workload across multiple machines. 

I will have a local self hosted server that acts as a “master node”. This will host the stuff like 
- surrealDB database
- temporal server (and the Postgres database)
- seaweedFS file system
- the dashboard (so the Litestar service and the nginx reverse proxy service that is exposed via tor)

But then there are the scanner nodes. These will be individual single board computers. Most likely all of them will be these “Le Potato” machines by Libre Computers.

https://libre.computer/products/aml-s905x-cc/

I will have them running Debian 12

My goal for these is to have them act as the “worker nodes” sort of “link up” with the master node, and be assigned tasks. These tasks will likely be broken down into 

- targets to scan
- tools to use for the scans
- maybe proxychains config files to use? 

And they will report back to the master node which will load the info into the database.


For the AI based summaries, I will have a server with a nicer AMD GPU (we typically refer to it as “gpu” as that is its hostname but it can also be called Ollama node or whatever). This will be running an Ollama service that the master node will be able to access, and provide with the latest scan results and prompt it for more detailed summaries.


Now that I’m really thinking about it, having this ollama node use Phidata agents so that it can search the web to create more informative summaries would be cool 

Please help me flesh out this idea for the system by asking questions and providing suggestions for elements of the project that I may not have considered yet

Once I feel confident about our plans we will begin to establish the projects file system in its git repository, and begin to dive into development. 